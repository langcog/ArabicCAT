---
title: "Arabic CDI-CAT"
author: "George"
date: "5/12/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(mirt)
require(mirtCAT)
require(readxl)
require(kableExtra)
source("IRT_helpers.R")
```

## Load JISH Data

```{r load-data, echo=F}
# from Haifa Alroqi May 13, 2022 - JISH CDI (JACDI) norms 
# The data file has WG and WS. Column BXW (total.produce) represents the total number of words produced by the whole sample. 
# Column BXV (total.understand) represents the total number of words comprehended by, I think, the whole sample. 
# I assume JISH initially used the vocabulary list of WS (which has the 550 words from WG and additional 348 words that are specific to WS) to collect data on both expressive and receptive vocabulary size of the whole sample. 
# Columns BYG (age.months) and BYH (age.group) can help us distinguish between WG and WS. WG is for children aged 8-16 months; WS is for children aged 17-36 months. 
sheets <- readxl::excel_sheets(path="data/JISH - CDI Data.xlsx")

raw <- read_xlsx(path="data/JISH - CDI Data.xlsx", sheet="JACDI Data")

notes <- read_xlsx(path="data/JISH - CDI Data.xlsx", sheet="Notes")
# note there are red highlighted columns that were not included in the paper form (so maybe discard?)
# also: "yellow highlight cells means we don't know what the word is in Arabic or we don't know what the column represents"
codebook <- read_xlsx(path="data/JISH - CDI Data.xlsx", sheet="Codebook")

## new data from Haifa Alroqi June 7, 2022
sheets_wg <- readxl::excel_sheets(path="data/Alroqi et al. 2020 - Saudi CDI - WG.xlsx")
raw_wg <- read_xlsx(path="data/Alroqi et al. 2020 - Saudi CDI - WG.xlsx", sheet="Saudi CDI - WG")
notes_wg <- read_xlsx(path="data/Alroqi et al. 2020 - Saudi CDI - WG.xlsx", sheet="Notes")

sheets_ws <- readxl::excel_sheets(path="data/Alroqi et al. 2020 - Saudi CDI - WS.xlsx")
raw_ws <- read_xlsx(path="data/Alroqi et al. 2020 - Saudi CDI - WS.xlsx", sheet="Saudi CDI - WS")
notes_ws <- read_xlsx(path="data/Alroqi et al. 2020 - Saudi CDI - WS.xlsx", sheet="Notes")

intersect(raw_wg[1,], raw_ws[1,])
```

Are 'ant.1.u' and 'ant.1.p' understanding and production (on WG form)? 
But then why would there be 'ant.2.u' *and* 'ant.2.p'?

### Notes

```{r notes, echo=F}
# "JACDI WS has 898 words"                                                                                                 
# "JACDI WG has 550 word" 
# "some words are repeated in the data file here; e.g., ant, so we gave it numbers: ant.1.u, ant.1.p, ant.2.u, ant.2.p, .."
print(notes)
```

### Codebook

```{r}
na.omit(unique(codebook$`Variable Values`))
```

## Clean data

```{r create-item-dictionary, echo=F}
#cat_names <- names(raw)[which(!grepl("...", names(raw)))] # contains categories
# what are columns 1:104 ? gestures..? not words?
category = c(rep(names(raw)[105], 55), # "Sound Effects and Animal Sounds"
             rep(names(raw)[160], 113), # "Animals (Real or Toy)"
             rep(names(raw)[273], 61) ) # Toys
names(raw)[334] # Vehicles (Real or Toy)
names(raw)[373] # Food and Drink
names(raw)[554] # Clothing
names(raw)[641] # "Body Parts"
names(raw)[714] # "Small Household Items"
names(raw)[859] # "Furniture and Rooms"
names(raw)[968] # Outside Things
names(raw)[211] # People
names(raw)[1128] # "Games and Routines"
names(raw)[1229] # "Action words"
names(raw)[1522] # Descriptive Words
names(raw)[1701] # "Words About Time"
names(raw)[1728] # "Question Words"
names(raw)[1741] # Pronouns
names(raw)[1786] # Negation words
names(raw)[1809] # Quantifiers
names(raw)[1870] # "Prepositions and Locations"
names(raw)[1913] # "Connecting Words and Letters" 
# final word index: 2010 ("...2010")
names(raw)[2011:2017]
arabic_names <- unlist(raw[2,])
col_names <- unlist(raw[1,])

items <- bind_cols(definition=arabic_names[8:1988], uni_lemma=col_names[8:1988])

col_names[which(is.na(col_names))] = paste0("na.",1:23)

names(raw) = col_names

# have a bunch of entirely NA columns that need to be removed
# (Columns 159, 272, 333, 372, 553, and 18 more)
raw2 <- raw[3:nrow(raw),-which(is.na(items$definition))] # 645x1997
items <- items %>% filter(!is.na(definition)) # 1961

d_demo = raw[3:nrow(raw),c(1:7, 1989:2017)] # last three columns are na.21 - na.23 - check and drop these?

d_demo <- d_demo %>% mutate(age = as.numeric(age.months),
                            production = as.numeric(total.produce),
                            comprehension = as.numeric(total.understand)) %>%
  select(-age.months, -total.produce, -total.understand)

# cut out first signs, starting talk, phrases, first gestures, games.routines, actions.objects, 
# pretend.parent, and imitate.adults
raw2 <- raw2[,105:1906]
# at the end, cut out word endings, how use, complexity, the totals columns etc.

# now we need to separate production (".p") and comprehension (".c") columns
prod_voc <- raw2[,which(endsWith(names(raw2), ".p"))]
comp_voc <- raw2[,which(endsWith(names(raw2), ".u"))]

save(file="data/Arabic_data.Rds", "prod_voc", "comp_voc", "d_demo")
```

```{r load-data}
load("data/Arabic_data.Rds")

d_mat <- prod_voc %>% 
  #select(-data_id) %>% 
  data.frame %>%
  data.matrix

too_young <- which(d_demo$age < 12) # 83 children too young to be producing words...

no_words <- which(d_demo$production==0 & d_demo$age>=12) # 9 additional children not producing

young_not_producing = c(too_young, no_words)

table(d_demo$age_mos) %>% kable(col.names=c("Age","N"))

d_demo <- d_demo %>% mutate(sex = ifelse(gender=="1", "Male", "Female")) %>% # # gender 1=male, 2=female (from codebook)
  select(-gender)
```

We use the provided production data from a total of `r nrow(d_demo)` participants. 
From this data we remove `r length(too_young)` children <12 months of age, who should not be producing any words yet. 
We also remove an additional `r length(no_words)` children 12+ months of age who are not yet producing any words, as these children cannot be used to fit the IRT models.
The production sumscores by age for the remaining children are shown below.

```{r}
ggplot(d_demo, aes(x = age, y = production, color = sex)) +
  geom_jitter(alpha = .2) + theme_bw() + xlab("Age (months)") + ylab("Production Sumscore")
```


## Fit IRT Models


```{r psycho-models_1pl, echo=F, eval = RUN_MODELS}
set.seed(1234)

mod_1pl <- mirt(d_mat, 1, itemtype='Rasch', verbose=TRUE, technical=list(NCYCLES=1000))

coefs_1pl <- as_tibble(coef(mod_1pl, simplify = TRUE)$items) %>%
  mutate(definition = rownames(coef(mod_1pl, simplify = TRUE)$items))
fscores_1pl <- tibble(data_id = rownames(d_mat), 
                             ability = fscores(mod_1pl, method = "MAP")[,1])

save(file = "data/arabic_mod_1pl.Rds", "mod_1pl", "fscores_1pl", "coefs_1pl")
```

```{r psycho-2pl_coefs, echo=F, eval = RUN_MODELS}
mod_2pl <- mirt(d_mat, 1, itemtype='2PL', verbose=TRUE,  technical=list(NCYCLES=3000))

coefs_2pl <- as_tibble(coef(mod_2pl, simplify = TRUE)$items) %>%
  mutate(definition = rownames(coef(mod_2pl, simplify = TRUE)$items))
fscores_2pl <- tibble(data_id = rownames(d_mat), 
                             ability = fscores(mod_2pl, method = "MAP")[,1])

save(file = "data/arabic_mod_2pl.Rds", "mod_2pl","fscores_2pl", "coefs_2pl")
```


```{r psycho-fit_irt_3pl, echo=F, eval = RUN_MODELS}
mod_3pl <- mirt::mirt(d_mat, 1, itemtype='3PL', verbose=TRUE, 
                      technical=list(NCYCLES=4000))

coefs_3pl <- as_tibble(coef(mod_3pl, simplify = TRUE)$items) %>%
  mutate(definition = rownames(coef(mod_3pl, simplify = TRUE)$items))
fscores_3pl <- tibble(data_id = rownames(d_mat), 
                             ability = fscores(mod_3pl, method = "MAP")[,1])

save(file = "data/arabic_mod_3pl.Rds", "mod_3pl","fscores_3pl", "coefs_3pl")
```



```{r psycho-models_load, echo=F}
load("data/arabic_mod_1pl.Rds")
load("data/arabic_mod_2pl.Rds")
load("data/arabic_mod_3pl.Rds")
```


## Model comparison.

Compared to the Rasch model, the 2PL model fits better and is preferred by both AIC and BIC.

```{r, anovas, include=F}

mc1 <- get_anova_table(mod_1pl, mod_2pl, c("Rasch", "2PL"))
mc2 <- get_anova_table(mod_2pl, mod_3pl, c("2PL", "3PL"))
```


```{r, echo=F}
kable(mc1, digits=2, 
      caption="Comparison of Rasch and 2PL models.") %>%
      html_table_width(c(60, 80, 80, 80, 50))
```

The 2PL is favored over the 3PL model by BIC, although AIC prefers the 3PL.


```{r, echo=F}
kable(mc2, digits=2, 
      caption="Comparison of 2PL and 3PL models.") %>%
      html_table_width(c(60, 80, 80, 80, 50))
```


The 2PL is preferred over both the Rasch (1PL) model and the 3PL model by BIC, so we do the rest of our analyses using the 2PL model as the basis.
Next we look for linear dependencies (LD) among the items, and also check for ill-fitting items. We will remove any items that show both strong LD and poor fit.


# Item bank

## Examine Linear Dependencies

```{r, linear-ind, echo=F, eval=RUN_MODELS}
#res = residuals(mod_2pl, type = 'JSI') # finished (slowly) for 166 items, but error on 167th:
# Could not invert information matrix; model likely is not empirically identified.Error in x[1L:2L, "a1"] : subscript out of bounds
# Error in x[1L:2L, "a1"] : subscript out of bounds

res = residuals(mod_2pl, type = 'LD') # upper diag are standardized residuals in the form of signed Cramers V coefficients
save(file="data/Arabic_LD.Rds", "res")
# most values near 0, but some +/-300...but Cramer's V is supposed to be 0-1 ???
```

```{r, linear-dep-tab, echo=F, caption="Items showing moderate LD with 9 or more other items."}
load(here("data/Arabic_LD.Rds"))

# no association = abs(V) < .1 no association, .3 is moderate, and .5+ is strong

hiLDvio = get_LD_violations(res, assoc_str=.5)
hiLDvio_words = coefs_2pl[which(hiLDvio>10),]$definition # 341..

modLDvio = get_LD_violations(res)
modLDvio_words = coefs_2pl[which(modLDvio>10),]$definition # 868 words have moderate LD ... 


# ToDo: try just removing the few items with many violations and then re-fit the model

#kable(matrix(coefs_2pl[which(modLDvio>10),]$definition, ncol=2)) %>% 
#  html_table_width(rep(150, 2))
```

We examined each item for pairwise linear dependencies (LD) with other items using $\chi^{2}$ (Chen & Thissen, 1997), and found that `r length(hiLDvio_words)` items show strong LD (Cramer's $V \geq 0.5$), and `r length(modLDvio_words)` items show moderate LD ($V \geq 0.3$) with at least 10 other items. 
This suggests multidimensionality, and we may want to look into exploratory factor analysis.


## Ill-fitting items

Our next goal is to determine if all items should be included in the item bank. Items that have very bad properties should probably be dropped. We will prune any ill-fitting items ($\chi^{2}*_{df}$ $p<.001$) from the full 2PL model that *also* showed strong LD.

```{r, item-fit-2pl, echo=F, eval=RUN_MODELS}
# use the 2PL fitted to all items
itfit2pl <- itemfit(mod_2pl, fit_stats = "X2", method="MAP") # need to use MAP estimates?
# had to switch from S_X2 because it can't handle missing data (all WG subjects)
# Unable to compute normalization constant for EAP estimates; consider using MAP estimates instead.
# The following factor score estimates failed to converge successfully:
#    489,516,557,559,560,566,574,601,611

itfit2pl_x2 <- itemfit(mod_2pl, fit_stats = 'X2*_df', Theta=fscores_2pl) # [-c(713,5132),]
# 'X2*_df' : Stone's (2000) fit statistics that require parametric bootstrapping to obtain scaled versions of the X2* and degrees of freedom
# 'PV_Q1*' : Chalmers and Ng's (2017) plausible-value variant of the Q1 statistic that uses parametric bootstrapping to obtain a suitable empirical distribution
save(file="data/Arabic_2pl_itemfits.Rds", "itfit2pl") #  "itfit2pl_x2"
```

```{r, echo=F}
load("data/Arabic_2pl_itemfits.Rds")
#bad_items2pl = which(itfit2pl$p.S_X2 < .05) # 0!
#bad_items2pl = which(itfit2pl$p.S_X2 < .01) # 0 with p<.01 
bad_items2pl = which(itfit2pl$p.X2 < .001) # 232 items
#bad_items2pl_x2 = which(itfit2pl_x2$p.X2_star_scaled < .001) # 223 with p<.01, 142 with p<.001
#print(itfit1)
#med_rmsea = median(itfit2pl_x2$RMSEA.X2_star_scaled, na.rm=T) # .01
#length(which(itfit2pl$RMSEA.X2_star_scaled > .02))

# items showing strong LD and poor fit
bad_ld_fit = intersect(which(hiLDvio > 0), bad_items2pl) # 206
```

`r length(bad_items2pl)` items did not fit well in the full 2PL model, and these items are shown below. 

```{r, include=F, echo=F}
kable(matrix(itfit2pl$item[bad_items2pl], ncol=8)) %>% 
  html_table_width(rep(150, 8))
```

### Plot 2PL Coefficients

Next, we examine the coefficients of the 2PL model. 
Items that are estimated to be very easy (e.g., mommy, daddy, ball) or very difficult (would, were, country) are highlighted, as well as those at the extremes of discrimination (a1).

```{r, fig.width=8, fig.height=6, echo=F}
ggplot(coefs_2pl, 
       aes(x = a1, y = d)) + 
  geom_point(alpha=.7) + 
  ggrepel::geom_label_repel(data = filter(coefs_2pl, 
                                          a1 < 1.5   | d > 2.5 | 
                                          a1 > 4.5 | d < -5.5), 
                            aes(label = definition)) + theme_bw()
```



Next, we will run simulated CATs on the data from the `r nrow(d_mat)` 12-36 month-olds. 
However, since many of these participants' data are from the CDI:WG form, there are many missing responses (compared to the CDI:WS). 
In order to run the simulated CATs, we impute the missing data using the participants' estimated ability and the 2PL model.
Overall, `r round(100*sum(is.na(d_mat))/length(d_mat),1)`% of the data was missing, and will be imputed.

```{r, impute-missing-data, echo=F, warning=F}
# To run the CAT simulations, we need to impute the missing responses
set.seed(123)
fs <- fscores(mod_2pl)
d_mat_imp = imputeMissing(mod_2pl, Theta=fs) # fscores_2pl has just ability, not discrim
# Imputing too much data can lead to very conservative results. Use with caution.
```

## Fixed-length CATs

```{r, fixed-length-CAT, echo=F, eval = RUN_MODELS}
cores = detectCores()
cl = makeCluster(cores[1]-1) # don't overload computer
registerDoParallel(cl)

f25 = doCAT_fixed_length(d_mat_imp, mod_2pl, min_items=25)
f50 = doCAT_fixed_length(d_mat_imp, mod_2pl, min_items=50)
f75 = doCAT_fixed_length(d_mat_imp, mod_2pl, min_items=75)
f100 = doCAT_fixed_length(d_mat_imp, mod_2pl, min_items=100)
f200 = doCAT_fixed_length(d_mat_imp, mod_2pl, min_items=200)
f300 = doCAT_fixed_length(d_mat_imp, mod_2pl, min_items=300)
f400 = doCAT_fixed_length(d_mat_imp, mod_2pl, min_items=400)
save("f25", "f50", "f75", "f100", 
     "f200", "f300", "f400", 
     file=here("data/fr_ws_wg_CAT_fixed_length.Rds"))

```
